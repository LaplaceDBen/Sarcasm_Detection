{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sarkasmus Klassifikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benit\\AppData\\Local\\Temp\\ipykernel_19132\\3457031542.py:26: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner.tuners import RandomSearch\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\benit\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import collections\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import csv\n",
    "import random\n",
    "import json\n",
    "\n",
    "\n",
    "import gensim\n",
    "import keras_tuner\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Word2Vec\n",
    "from keras.activations import relu, tanh, sigmoid, linear, gelu\n",
    "from keras.layers import (Bidirectional, Dense, Dropout, Embedding, GRU, LSTM,\n",
    "RNN)\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from kerastuner.tuners import RandomSearch\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "from lightgbm import LGBMClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier,\n",
    "ExtraTreesClassifier, GradientBoostingClassifier,\n",
    "RandomForestClassifier)\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, RidgeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, ComplementNB, CategoricalNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC, OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7302     151\n",
      "24815     39\n",
      "Name: headline, dtype: int64\n",
      "24815    39\n",
      "23598    38\n",
      "Name: headline, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('Sarcasm_Headlines_Dataset_v2.json', lines=True)\n",
    "#article URLs not needed\n",
    "df.drop(columns=['article_link'], inplace=True)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "#display line with most words\n",
    "print(df['headline'].str.split().apply(len).sort_values(ascending=False).head(2))\n",
    "#delete headlines with more than 40 words\n",
    "df = df[df['headline'].str.split().apply(len) < 40]\n",
    "#remove Stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "print(df['headline'].str.split().apply(len).sort_values(ascending=False).head(2))\n",
    "#applay length of longest headline a variable\n",
    "max_len = df['headline'].str.split().apply(len).sort_values(ascending=False).head(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38212\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "#get number of diffrent words in headlines\n",
    "words = []\n",
    "for headline in df['headline']:\n",
    "    for word in headline.split():\n",
    "        words.append(word)\n",
    "print(len(set(words)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#kudos https://www.kaggle.com/code/madz2000/sarcasm-detection-with-glove-word2vec-83-accuracy#LOADING-THE-DATASET\n",
    "#remove square brackets, URLs and Noise\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "#Removing numbers as it can cause additional noise\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "\n",
    "#Removing the noisy text \n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_numbers(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['headline']=df['headline'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['thirtysomething',\n",
       "  'scientists',\n",
       "  'unveil',\n",
       "  'doomsday',\n",
       "  'clock',\n",
       "  'hair',\n",
       "  'loss'],\n",
       " ['dem',\n",
       "  'rep.',\n",
       "  'totally',\n",
       "  'nails',\n",
       "  'congress',\n",
       "  'falling',\n",
       "  'short',\n",
       "  'gender,',\n",
       "  'racial',\n",
       "  'equality'],\n",
       " ['eat', 'veggies:', 'deliciously', 'different', 'recipes'],\n",
       " ['inclement', 'weather', 'prevents', 'liar', 'getting', 'work'],\n",
       " ['mother',\n",
       "  'comes',\n",
       "  'pretty',\n",
       "  'close',\n",
       "  'using',\n",
       "  'word',\n",
       "  \"'streaming'\",\n",
       "  'correctly']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting text to format acceptable by gensim\n",
    "\n",
    "words = []\n",
    "for i in df.headline.values:\n",
    "    words.append(i.split())\n",
    "words[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# copy Dataset for ML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a copy of the dataframe\n",
    "df_ml = df.copy()\n",
    "#train test split\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(df_ml['headline'], df_ml['is_sarcastic'], test_size=0.25, random_state=42)\n",
    "#validation\n",
    "X_train_ml, X_val_ml, y_train_ml, y_val_ml = train_test_split(X_train_ml, y_train_ml, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDVecttorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17100, 20490)\n",
      "(4276, 20490)\n",
      "(7126, 20490)\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/eisgandar/sarcastic-headlines-detector-lstm\n",
    "#diffrent vectorizers\n",
    "tf_idf_word_vectorizer = TfidfVectorizer(analyzer = \"word\")\n",
    "tf_idf_word_vectorizer.fit(X_train_ml)\n",
    "\n",
    "x_train_vec = tf_idf_word_vectorizer.transform(X_train_ml)\n",
    "x_val_vec = tf_idf_word_vectorizer.transform(X_val_ml)\n",
    "x_test_vec = tf_idf_word_vectorizer.transform(X_test_ml)\n",
    "\n",
    "#x_train_vec.toarray()\n",
    "\n",
    "print(x_train_vec.shape)\n",
    "print(x_val_vec.shape)\n",
    "print(x_test_vec.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "C_vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Fit the vectorizer to the training data and transform both train and test data\n",
    "X_train_binary = C_vectorizer.fit_transform(X_train_ml).astype('float32')\n",
    "X_val_binary = C_vectorizer.transform(X_val_ml).astype('float32')\n",
    "X_test_binary = C_vectorizer.transform(X_test_ml).astype('float32')\n",
    "\n",
    "#The main advantage of using the binary vectorizer over the TF vectorizer is that it reduces the impact of features that occur frequently in the dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vectorizers\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "hashing_vectorizer = HashingVectorizer(binary=True)\n",
    "\n",
    "# Vectorize the data\n",
    "train_x_hashing = hashing_vectorizer.transform(X_train_ml)\n",
    "valid_x_hashing = hashing_vectorizer.transform(X_val_ml)\n",
    "test_x_hashing = hashing_vectorizer.transform(X_test_ml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37034, 100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Dimension of vectors we are generating\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "w2v_model = gensim.models.Word2Vec(sentences = words, window = 5, min_count = 1)\n",
    "w2v_model.wv.vectors.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(num_words=40000)\n",
    "tokenizer.fit_on_texts(words)\n",
    "#tokenized_train = tokenizer.texts_to_sequences(words)\n",
    "#x = sequence.pad_sequences(tokenized_train, maxlen = 20)\n",
    "sequences = tokenizer.texts_to_sequences(words)\n",
    "#max_len changed to the longest headline\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,  2307,   552,   930],\n",
       "       [    0,     0,     0, ..., 11228,  1972,  1787],\n",
       "       [    0,     0,     0, ..., 16405,   471,  1339],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,   942,   662,  1633],\n",
       "       [    0,     0,     0, ..., 37034,   811,  5884],\n",
       "       [    0,     0,     0, ...,  2940,   171,    92]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create weight matrix from word2vec gensim model\n",
    "def get_weight_matrix(model, vocab):\n",
    "    # total vocabulary size plus 0 for unknown words\n",
    "    vocab_size = len(vocab) + 1\n",
    "    # define weight matrix dimensions with all 0\n",
    "    weight_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
    "    # step vocab, store vectors using the Tokenizer's integer mapping\n",
    "    for word, i in vocab.items():\n",
    "        weight_matrix[i] = model.wv[word]\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting embedding vectors from word2vec and usings it as weights of non-trainable keras embedding layer\n",
    "embedding_vectors = get_weight_matrix(w2v_model, tokenizer.word_index)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, df.is_sarcastic , test_size = 0.2 , random_state = 187) \n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25 , random_state = 187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the model architecture\n",
    "# Refactoring of Dennis Code with CHATGPT\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(layers.Embedding(vocab_size, output_dim=100, weights=[embedding_vectors], trainable=True))\n",
    "\n",
    "    prev_units = hp.Int(\"prev_units\", min_value=8, max_value=96, step=2, default=96)\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        for layer_type in [LSTM, GRU]:\n",
    "            curr_units = hp.Int(f\"units_{i}\", min_value=8, max_value=prev_units, step=2)\n",
    "            prev_units = curr_units\n",
    "\n",
    "            model.add(Bidirectional(layer_type(units=curr_units,\n",
    "                                               recurrent_dropout=hp.Float(f\"recurrent_dropout_{i}\", min_value=0.0, max_value=0.9, step=0.1),\n",
    "                                               dropout=hp.Float(f\"dropout_{i}\", min_value=0.0, max_value=0.9, step=0.1),\n",
    "                                               activation=hp.Choice(f\"activation_{i}\", values=[\"relu\", \"tanh\", \"gelu\"]),\n",
    "                                               return_sequences=True),\n",
    "                                               name=f\"bidirectional_{layer_type.__name__.lower()}_{i}\"))\n",
    "\n",
    "    learning_rate_tuned = hp.Float(\"lr\", min_value=1e-4, max_value=1e-3, sampling=\"log\")\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate_tuned),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper class so callback works with tuner (ChatGPT)\n",
    "class TerminationOnNoImprovement(keras.callbacks.Callback):\n",
    "    def __init__(self, patience=10, restore_best_weights=True):\n",
    "        super(TerminationOnNoImprovement, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_weights = None\n",
    "        self.best_epoch = None\n",
    "        self.best_val_acc = None\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_weights = self.model.get_weights()\n",
    "        self.best_epoch = 0\n",
    "        self.best_val_acc = -float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_acc = logs.get('val_accuracy')\n",
    "        if val_acc > self.best_val_acc:\n",
    "            self.best_weights = self.model.get_weights()\n",
    "            self.best_epoch = epoch\n",
    "            self.best_val_acc = val_acc\n",
    "        elif epoch - self.best_epoch >= self.patience:\n",
    "            print(f'Epoch {epoch}: early stopping')\n",
    "            self.model.stop_training = True\n",
    "            if self.restore_best_weights:\n",
    "                print(f'Restored model weights from epoch {self.best_epoch}')\n",
    "                self.model.set_weights(self.best_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from Tuner\\NLP_Tuner\\tuner0.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor _ in range(len(batch_sizes)):\\n    #batch_size = random.choice(batch_sizes)\\n    #print(f'Batch size: {batch_size}')\\n    tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=128, callbacks=[TerminationOnNoImprovement()])\\n    trial_best_model = tuner.get_best_models(num_models=1)[0]\\n    trial_best_hparams = tuner.get_best_hyperparameters(num_trials=1)[0]\\n    trial_best_val_acc = tuner.get_best_trial('val_accuracy').score\\n\\n    if trial_best_val_acc > best_val_acc:\\n        best_batch_size = batch_size\\n        best_model = trial_best_model\\n        best_hparams = trial_best_hparams\\n        best_val_acc = trial_best_val_acc\\n        #plot model\\n        plot_model(best_model, to_file='best_model.png', show_shapes=True, show_layer_names=True)\\n        #write best model to file\\n        best_model.save('best_model.h5')\\n        #write best hyperparameters to file\\n        with open('best_hparams.json', 'w') as f:\\n            json.dump(best_hparams.values, f)\\n            \\n\\nprint(f'Best batch size: {best_batch_size}')\\nprint(f'Best validation accuracy: {best_val_acc}')\\nprint(f'Best hyperparameters: {best_hparams.values}')\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model, objective='val_accuracy',\n",
    "    max_trials=100, executions_per_trial=1,\n",
    "    directory='Tuner',project_name='NLP_Tuner',seed=187\n",
    ")\n",
    "\n",
    "batch_sizes = [16,32, 64, 128, 256,512,1024,2048]\n",
    "\n",
    "\n",
    "best_batch_size = None; best_model = None; best_hparams = None; best_val_acc = -float('inf')\n",
    "'''\n",
    "for _ in range(len(batch_sizes)):\n",
    "    #batch_size = random.choice(batch_sizes)\n",
    "    #print(f'Batch size: {batch_size}')\n",
    "    tuner.search(x_train, y_train, epochs=50, validation_data=(x_val, y_val), batch_size=128, callbacks=[TerminationOnNoImprovement()])\n",
    "    trial_best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    trial_best_hparams = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    trial_best_val_acc = tuner.get_best_trial('val_accuracy').score\n",
    "\n",
    "    if trial_best_val_acc > best_val_acc:\n",
    "        best_batch_size = batch_size\n",
    "        best_model = trial_best_model\n",
    "        best_hparams = trial_best_hparams\n",
    "        best_val_acc = trial_best_val_acc\n",
    "        #plot model\n",
    "        plot_model(best_model, to_file='best_model.png', show_shapes=True, show_layer_names=True)\n",
    "        #write best model to file\n",
    "        best_model.save('best_model.h5')\n",
    "        #write best hyperparameters to file\n",
    "        with open('best_hparams.json', 'w') as f:\n",
    "            json.dump(best_hparams.values, f)\n",
    "            \n",
    "\n",
    "print(f'Best batch size: {best_batch_size}')\n",
    "print(f'Best validation accuracy: {best_val_acc}')\n",
    "print(f'Best hyperparameters: {best_hparams.values}')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, GRU, Dense, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "#best model after 50 first trials\n",
    "#best val_accuracy 80.08%\n",
    "'''Value             |Best Value So Far |Hyperparameter\n",
    "    38                |22                |prev_units\n",
    "    3                 |2                 |num_layers\n",
    "    58                |60                |units_0\n",
    "    0.2               |0.4               |recurrent_dropout_0\n",
    "    0.5               |0.7               |dropout_0\n",
    "    tanh              |tanh              |activation_0\n",
    "    0.0066263         |0.00010899        |lr\n",
    "    8                 |16                |units_1\n",
    "    0.8               |0.6               |recurrent_dropout_1\n",
    "    0                 |0.8               |dropout_1\n",
    "    tanh              |tanh              |activation_1\n",
    "    8                 |8                 |units_2\n",
    "    0.8               |0.4               |recurrent_dropout_2\n",
    "    0.8               |0.6               |dropout_2\n",
    "    tanh              |gelu              |activation_2'''\n",
    "# Defining Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "# Non-trainable embedding layer\n",
    "model.add(Embedding(vocab_size, output_dim=100, weights=[embedding_vectors], trainable=True))\n",
    "\n",
    "# LSTM \n",
    "model.add(Bidirectional(LSTM(units=8, activation='tanh', recurrent_dropout=0.4, dropout=0.7, return_sequences=True)))\n",
    "model.add(Bidirectional(GRU(units= 8, activation='tanh', recurrent_dropout=0.6, dropout=0.8, return_sequences=True)))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "#model.add(Flatten())  # Convert 2D tensor to 1D tensor\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.1), loss='binary_crossentropy', metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[0;32m      3\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, batch_size \u001b[39m=\u001b[39;49m \u001b[39m2056\u001b[39;49m , validation_data \u001b[39m=\u001b[39;49m (x_val,y_val) , epochs \u001b[39m=\u001b[39;49m \u001b[39m1000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[early_stopping])\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:963\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    960\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m   \u001b[39m# This is the first call of __call__, so we have to initialize.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m   initializers \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 963\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize(args, kwds, add_initializers_to\u001b[39m=\u001b[39;49minitializers)\n\u001b[0;32m    964\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m   \u001b[39m# At this point we know that the initialization is complete (or less\u001b[39;00m\n\u001b[0;32m    966\u001b[0m   \u001b[39m# interestingly an exception was raised) so we no longer need a lock.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph \u001b[39m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph_deleter \u001b[39m=\u001b[39m FunctionDeleter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_concrete_stateful_fn \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_get_concrete_function_internal_garbage_collected(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    786\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n\u001b[0;32m    788\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minvalid_creator_scope\u001b[39m(\u001b[39m*\u001b[39munused_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2523\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2521\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2522\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 2523\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   2524\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2760\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2758\u001b[0m   \u001b[39m# Only get placeholders for arguments, not captures\u001b[39;00m\n\u001b[0;32m   2759\u001b[0m   args, kwargs \u001b[39m=\u001b[39m placeholder_dict[\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m-> 2760\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   2762\u001b[0m graph_capture_container \u001b[39m=\u001b[39m graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_capture_func_lib  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2763\u001b[0m \u001b[39m# Maintain the list of all captures\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2670\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2665\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   2666\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2667\u001b[0m ]\n\u001b[0;32m   2668\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   2669\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2670\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   2671\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   2672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   2673\u001b[0m         args,\n\u001b[0;32m   2674\u001b[0m         kwargs,\n\u001b[0;32m   2675\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   2676\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   2677\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   2678\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   2679\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   2680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   2681\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   2682\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2684\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2685\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2686\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2687\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[39mwith\u001b[39;00m default_graph\u001b[39m.\u001b[39m_variable_creator_scope(scope, priority\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m):  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[39m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[39m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[39mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[39m=\u001b[39m weak_wrapped_fn()\u001b[39m.\u001b[39m__wrapped__(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    678\u001b[0m   \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1222\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[39m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[39;00m\n\u001b[0;32m   1221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1222\u001b[0m   \u001b[39mreturn\u001b[39;00m autograph\u001b[39m.\u001b[39;49mconverted_call(\n\u001b[0;32m   1223\u001b[0m       original_func,\n\u001b[0;32m   1224\u001b[0m       args,\n\u001b[0;32m   1225\u001b[0m       kwargs,\n\u001b[0;32m   1226\u001b[0m       options\u001b[39m=\u001b[39;49mautograph\u001b[39m.\u001b[39;49mConversionOptions(\n\u001b[0;32m   1227\u001b[0m           recursive\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1228\u001b[0m           optional_features\u001b[39m=\u001b[39;49mautograph_options,\n\u001b[0;32m   1229\u001b[0m           user_requested\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1230\u001b[0m       ))\n\u001b[0;32m   1231\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[39m=\u001b[39m converted_f(\u001b[39m*\u001b[39meffective_args)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file42nj3hwr.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(step_function), (ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m), ag__\u001b[39m.\u001b[39;49mld(iterator)), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py:1146\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m     run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1143\u001b[0m         run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     )\n\u001b[0;32m   1145\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1146\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1147\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1148\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1149\u001b[0m )\n\u001b[0;32m   1150\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1315\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1310\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1311\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1314\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1315\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2891\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2889\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2890\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2891\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3692\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3690\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3691\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3692\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py:1135\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1135\u001b[0m     outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1136\u001b[0m     \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m     \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\engine\\training.py:997\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n\u001b[0;32m    996\u001b[0m \u001b[39m# Run backwards pass.\u001b[39;00m\n\u001b[1;32m--> 997\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mminimize(loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainable_variables, tape\u001b[39m=\u001b[39;49mtape)\n\u001b[0;32m    998\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_metrics(x, y, y_pred, sample_weight)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:576\u001b[0m, in \u001b[0;36mOptimizerV2.minimize\u001b[1;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mminimize\u001b[39m(\u001b[39mself\u001b[39m, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, tape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    546\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Minimize `loss` by updating `var_list`.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \n\u001b[0;32m    548\u001b[0m \u001b[39m    This method simply computes gradient using `tf.GradientTape` and calls\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 576\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_gradients(\n\u001b[0;32m    577\u001b[0m         loss, var_list\u001b[39m=\u001b[39;49mvar_list, grad_loss\u001b[39m=\u001b[39;49mgrad_loss, tape\u001b[39m=\u001b[39;49mtape\n\u001b[0;32m    578\u001b[0m     )\n\u001b[0;32m    579\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_gradients(grads_and_vars, name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:634\u001b[0m, in \u001b[0;36mOptimizerV2._compute_gradients\u001b[1;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[0;32m    632\u001b[0m var_list \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(var_list)\n\u001b[0;32m    633\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mname_scope(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/gradients\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     grads_and_vars \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_gradients(\n\u001b[0;32m    635\u001b[0m         tape, loss, var_list, grad_loss\n\u001b[0;32m    636\u001b[0m     )\n\u001b[0;32m    638\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assert_valid_dtypes(\n\u001b[0;32m    639\u001b[0m     [\n\u001b[0;32m    640\u001b[0m         v\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    643\u001b[0m     ]\n\u001b[0;32m    644\u001b[0m )\n\u001b[0;32m    646\u001b[0m \u001b[39mreturn\u001b[39;00m grads_and_vars\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:510\u001b[0m, in \u001b[0;36mOptimizerV2._get_gradients\u001b[1;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_gradients\u001b[39m(\u001b[39mself\u001b[39m, tape, loss, var_list, grad_loss\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    509\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 510\u001b[0m     grads \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mgradient(loss, var_list, grad_loss)\n\u001b[0;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\u001b[39mzip\u001b[39m(grads, var_list))\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[39m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[39m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m ops\u001b[39m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[39m=\u001b[39m imperative_grad\u001b[39m.\u001b[39;49mimperative_grad(\n\u001b[0;32m   1114\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,\n\u001b[0;32m   1115\u001b[0m     flat_targets,\n\u001b[0;32m   1116\u001b[0m     flat_sources,\n\u001b[0;32m   1117\u001b[0m     output_gradients\u001b[39m=\u001b[39;49moutput_gradients,\n\u001b[0;32m   1118\u001b[0m     sources_raw\u001b[39m=\u001b[39;49mflat_sources_raw,\n\u001b[0;32m   1119\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49munconnected_gradients)\n\u001b[0;32m   1121\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[39m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_watched_variables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape\u001b[39m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mUnknown value for unconnected_gradients: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeGradient(\n\u001b[0;32m     68\u001b[0m     tape\u001b[39m.\u001b[39;49m_tape,  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m     target,\n\u001b[0;32m     70\u001b[0m     sources,\n\u001b[0;32m     71\u001b[0m     output_gradients,\n\u001b[0;32m     72\u001b[0m     sources_raw,\n\u001b[0;32m     73\u001b[0m     compat\u001b[39m.\u001b[39;49mas_str(unconnected_gradients\u001b[39m.\u001b[39;49mvalue))\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m forward_pass_name_scope \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39;49mout_grads)\n\u001b[0;32m    161\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn(mock_op, \u001b[39m*\u001b[39mout_grads)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:393\u001b[0m, in \u001b[0;36m_WhileGrad\u001b[1;34m(op, *grads)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39m# We compute the gradient for the sub-graph between trainable ys and xs\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m# with non-None incoming gradients. We later pad the None's to the list of\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39m# outputs.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m ys, xs, non_none_grads \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m[(y, x, grad) \u001b[39mfor\u001b[39;00m (y, x, grad) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\n\u001b[0;32m    391\u001b[0m     body_graph\u001b[39m.\u001b[39moutputs, body_graph\u001b[39m.\u001b[39minputs, grads) \u001b[39mif\u001b[39;00m grad \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m])\n\u001b[1;32m--> 393\u001b[0m body_grad_graph, args \u001b[39m=\u001b[39m _create_grad_func(\n\u001b[0;32m    394\u001b[0m     ys, xs, non_none_grads, cond_graph, body_graph,\n\u001b[0;32m    395\u001b[0m     util\u001b[39m.\u001b[39;49munique_grad_fn_name(body_graph\u001b[39m.\u001b[39;49mname), op, maximum_iterations,\n\u001b[0;32m    396\u001b[0m     stateful_parallelism)\n\u001b[0;32m    398\u001b[0m \u001b[39mif\u001b[39;00m body_grad_graph\u001b[39m.\u001b[39mwhile_op_needs_rewrite:\n\u001b[0;32m    399\u001b[0m   \u001b[39m# Modify 'op' to output the intermediate accumulators needed by the grad\u001b[39;00m\n\u001b[0;32m    400\u001b[0m   \u001b[39m# function.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m   \u001b[39m# NOTE(skyewm): if there are any active sessions, this modification to `op`\u001b[39;00m\n\u001b[0;32m    402\u001b[0m   \u001b[39m# may make them unrunnable!\u001b[39;00m\n\u001b[0;32m    404\u001b[0m   cond_graph\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_rewritten\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:695\u001b[0m, in \u001b[0;36m_create_grad_func\u001b[1;34m(ys, xs, grads, cond_graph, body_graph, name, while_op, maximum_iterations, stateful_parallelism)\u001b[0m\n\u001b[0;32m    692\u001b[0m args \u001b[39m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(grads)\n\u001b[0;32m    693\u001b[0m \u001b[39m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m# `external_captures`.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m grad_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    696\u001b[0m     name,\n\u001b[0;32m    697\u001b[0m     \u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49margs: _grad_fn(ys, xs, args, body_graph),\n\u001b[0;32m    698\u001b[0m     args, {},\n\u001b[0;32m    699\u001b[0m     func_graph\u001b[39m=\u001b[39;49m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[0;32m    700\u001b[0m                                        maximum_iterations, while_op,\n\u001b[0;32m    701\u001b[0m                                        body_graph_inputs, body_graph_outputs),\n\u001b[0;32m    702\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39;49mstateful_parallelism)\n\u001b[0;32m    704\u001b[0m \u001b[39m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[39m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[39mfor\u001b[39;00m external_capture, internal_capture \u001b[39min\u001b[39;00m grad_func_graph\u001b[39m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1247\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1247\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39mfunc_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1249\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1251\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m   1252\u001b[0m     convert, func_outputs, expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:697\u001b[0m, in \u001b[0;36m_create_grad_func.<locals>.<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    692\u001b[0m args \u001b[39m=\u001b[39m [counter, maximum_iterations, total_iters] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(grads)\n\u001b[0;32m    693\u001b[0m \u001b[39m# Note: The returned function does not have `args` in the list of\u001b[39;00m\n\u001b[0;32m    694\u001b[0m \u001b[39m# `external_captures`.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m grad_func_graph \u001b[39m=\u001b[39m func_graph_module\u001b[39m.\u001b[39mfunc_graph_from_py_func(\n\u001b[0;32m    696\u001b[0m     name,\n\u001b[1;32m--> 697\u001b[0m     \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs: _grad_fn(ys, xs, args, body_graph),\n\u001b[0;32m    698\u001b[0m     args, {},\n\u001b[0;32m    699\u001b[0m     func_graph\u001b[39m=\u001b[39m_WhileBodyGradFuncGraph(name, cond_graph, body_graph,\n\u001b[0;32m    700\u001b[0m                                        maximum_iterations, while_op,\n\u001b[0;32m    701\u001b[0m                                        body_graph_inputs, body_graph_outputs),\n\u001b[0;32m    702\u001b[0m     acd_record_initial_resource_uses\u001b[39m=\u001b[39mstateful_parallelism)\n\u001b[0;32m    704\u001b[0m \u001b[39m# Update the list of outputs with tensors corresponding to the captured\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[39m# tensors. We capture 3 types of tensors when building the grad fn:\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[39m# 1. Accumulators for forward graph intermediates which are not loop\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[39m# 2. Resources, which are output as is.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \u001b[39m# 3. Forward graph loop invariants, which are output as is.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[39mfor\u001b[39;00m external_capture, internal_capture \u001b[39min\u001b[39;00m grad_func_graph\u001b[39m.\u001b[39mcaptures:\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:753\u001b[0m, in \u001b[0;36m_grad_fn\u001b[1;34m(ys, xs, args, func_graph)\u001b[0m\n\u001b[0;32m    746\u001b[0m grad_ys \u001b[39m=\u001b[39m args[\u001b[39m3\u001b[39m:]\n\u001b[0;32m    748\u001b[0m \u001b[39m# Build the gradient graph. Note that this builds the gradient computation of\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[39m# func_graph in the current graph, which requires capturing tensors from\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[39m# func_graph. The captured func_graph tensors are resolved to external tensors\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[39m# after the forward While op has been rewritten in _resolve_grad_captures.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[39m# TODO(srbs): Mark GradientsHelper as public?\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m grad_outs \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    754\u001b[0m     ys, xs, grad_ys\u001b[39m=\u001b[39;49mgrad_ys, src_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    755\u001b[0m     unconnected_gradients\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mzero\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    757\u001b[0m \u001b[39m# TODO(b/118712257): Handle the case when grad_outs has None's e.g. when there\u001b[39;00m\n\u001b[0;32m    758\u001b[0m \u001b[39m# is a tf.StopGradient in the loop body.\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(g \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m grad_outs)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:695\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[1;32m--> 695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    696\u001b[0m                              \u001b[39mlambda\u001b[39;49;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:329\u001b[0m, in \u001b[0;36m_MaybeCompile\u001b[1;34m(scope, op, func, grad_fn)\u001b[0m\n\u001b[0;32m    326\u001b[0m     xla_compile \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m xla_compile:\n\u001b[1;32m--> 329\u001b[0m   \u001b[39mreturn\u001b[39;00m grad_fn()  \u001b[39m# Exit early\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# If the gradients are supposed to be compiled separately, we give them a\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# _XlaScope name that is based on the name_scope of the gradients.  Otherwise\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39m# they just inherit the existing _XlaScope name, which lets them be merged\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39m# together with the non-gradient computation.\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[39mif\u001b[39;00m xla_separate_compiled_gradients:\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:696\u001b[0m, in \u001b[0;36m_GradientsHelper.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39mwith\u001b[39;00m src_graph\u001b[39m.\u001b[39m_original_op(op):\n\u001b[0;32m    691\u001b[0m   \u001b[39m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m grad_fn:\n\u001b[0;32m    693\u001b[0m     \u001b[39m# If grad_fn was found, do not use SymbolicGradient even for\u001b[39;00m\n\u001b[0;32m    694\u001b[0m     \u001b[39m# functions.\u001b[39;00m\n\u001b[0;32m    695\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[1;32m--> 696\u001b[0m                              \u001b[39mlambda\u001b[39;00m: grad_fn(op, \u001b[39m*\u001b[39;49mout_grads))\n\u001b[0;32m    697\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    698\u001b[0m     \u001b[39m# For function call ops, we add a 'SymbolicGradient'\u001b[39;00m\n\u001b[0;32m    699\u001b[0m     \u001b[39m# node to the graph to compute gradients.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     in_grads \u001b[39m=\u001b[39m _MaybeCompile(grad_scope, op, func_call,\n\u001b[0;32m    701\u001b[0m                              \u001b[39mlambda\u001b[39;00m: _SymGrad(op, out_grads))\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1378\u001b[0m, in \u001b[0;36m_MulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1375\u001b[0m   gx \u001b[39m=\u001b[39m gen_math_ops\u001b[39m.\u001b[39mmul(grad, y)\n\u001b[0;32m   1376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m   gx \u001b[39m=\u001b[39m array_ops\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m-> 1378\u001b[0m       math_ops\u001b[39m.\u001b[39mreduce_sum(gen_math_ops\u001b[39m.\u001b[39;49mmul(grad, y), rx), sx)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m skip_input_indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m skip_input_indices:\n\u001b[0;32m   1380\u001b[0m   gy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6588\u001b[0m, in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6586\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m   6587\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[1;32m-> 6588\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   6589\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mMul\u001b[39;49m\u001b[39m\"\u001b[39;49m, x\u001b[39m=\u001b[39;49mx, y\u001b[39m=\u001b[39;49my, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   6590\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   6591\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1044\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[39mif\u001b[39;00m (op_type \u001b[39min\u001b[39;00m optimized_reduction_ops \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m     \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39moutput_all_intermediates() \u001b[39mand\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m     \u001b[39mall\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mgraph \u001b[39mis\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[39mnot\u001b[39;00m util\u001b[39m.\u001b[39mgraph_wrapped_for_higher_order_tape_gradients(\n\u001b[0;32m   1033\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph)):\n\u001b[0;32m   1034\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_move_op_to_forward_graph(\n\u001b[0;32m   1035\u001b[0m       op_type,\n\u001b[0;32m   1036\u001b[0m       inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m       op_def\u001b[39m=\u001b[39mop_def,\n\u001b[0;32m   1042\u001b[0m       compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[1;32m-> 1044\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(_WhileBodyGradFuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(\n\u001b[0;32m   1045\u001b[0m     op_type,\n\u001b[0;32m   1046\u001b[0m     inputs,\n\u001b[0;32m   1047\u001b[0m     dtypes\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   1048\u001b[0m     input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   1049\u001b[0m     name\u001b[39m=\u001b[39;49mname,\n\u001b[0;32m   1050\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m   1051\u001b[0m     op_def\u001b[39m=\u001b[39;49mop_def,\n\u001b[0;32m   1052\u001b[0m     compute_device\u001b[39m=\u001b[39;49mcompute_device)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:733\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    731\u001b[0m   \u001b[39mif\u001b[39;00m ctxt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ctxt, \u001b[39m\"\u001b[39m\u001b[39mAddValue\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    732\u001b[0m     inp \u001b[39m=\u001b[39m ctxt\u001b[39m.\u001b[39mAddValue(inp)\n\u001b[1;32m--> 733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[0;32m    735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m(FuncGraph, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:800\u001b[0m, in \u001b[0;36mFuncGraph.capture\u001b[1;34m(self, tensor, name, shape)\u001b[0m\n\u001b[0;32m    790\u001b[0m       \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mInaccessibleTensorError(\n\u001b[0;32m    791\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m!r}\u001b[39;00m\u001b[39m is out of scope and cannot be used here. Use return \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mvalues, explicit Python locals or TensorFlow collections to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    797\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe tensor \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m!r}\u001b[39;00m\u001b[39m cannot be accessed from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, because \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    798\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mit was defined in \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mgraph\u001b[39m}\u001b[39;00m\u001b[39m, which is out of scope.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    799\u001b[0m     inner_graph \u001b[39m=\u001b[39m inner_graph\u001b[39m.\u001b[39mouter_graph\n\u001b[1;32m--> 800\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_helper(tensor, name)\n\u001b[0;32m    801\u001b[0m \u001b[39mreturn\u001b[39;00m tensor\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\while_v2.py:1207\u001b[0m, in \u001b[0;36m_WhileBodyGradFuncGraph._capture_helper\u001b[1;34m(self, tensor, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_graph\u001b[39m.\u001b[39mouter_graph\u001b[39m.\u001b[39mas_default():\n\u001b[0;32m   1206\u001b[0m   \u001b[39mwith\u001b[39;00m util\u001b[39m.\u001b[39mclear_control_inputs():\n\u001b[1;32m-> 1207\u001b[0m     tensor_list \u001b[39m=\u001b[39m list_ops\u001b[39m.\u001b[39;49mempty_tensor_list(\n\u001b[0;32m   1208\u001b[0m         element_dtype\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1209\u001b[0m         element_shape\u001b[39m=\u001b[39;49mtensor\u001b[39m.\u001b[39;49mshape,\n\u001b[0;32m   1210\u001b[0m         max_num_elements\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maximum_iterations,\n\u001b[0;32m   1211\u001b[0m         name\u001b[39m=\u001b[39;49m_build_accumulator_name(tensor))\n\u001b[0;32m   1212\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mextra_inputs\u001b[39m.\u001b[39mappend(tensor_list)\n\u001b[0;32m   1214\u001b[0m \u001b[39m# Push the intermediate tensor to the tensor list. This captures\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# `tensor_list`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\list_ops.py:54\u001b[0m, in \u001b[0;36mempty_tensor_list\u001b[1;34m(element_shape, element_dtype, max_num_elements, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m max_num_elements \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   max_num_elements \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m gen_list_ops\u001b[39m.\u001b[39;49mempty_tensor_list(\n\u001b[0;32m     55\u001b[0m     element_shape\u001b[39m=\u001b[39;49m_build_element_shape(element_shape),\n\u001b[0;32m     56\u001b[0m     element_dtype\u001b[39m=\u001b[39;49melement_dtype,\n\u001b[0;32m     57\u001b[0m     max_num_elements\u001b[39m=\u001b[39;49mmax_num_elements,\n\u001b[0;32m     58\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\ops\\gen_list_ops.py:62\u001b[0m, in \u001b[0;36mempty_tensor_list\u001b[1;34m(element_shape, max_num_elements, element_dtype, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[39m# Add nodes to the TensorFlow graph.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m element_dtype \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_type(element_dtype, \u001b[39m\"\u001b[39m\u001b[39melement_dtype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m     63\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mEmptyTensorList\u001b[39;49m\u001b[39m\"\u001b[39;49m, element_shape\u001b[39m=\u001b[39;49melement_shape,\n\u001b[0;32m     64\u001b[0m                          max_num_elements\u001b[39m=\u001b[39;49mmax_num_elements,\n\u001b[0;32m     65\u001b[0m                          element_dtype\u001b[39m=\u001b[39;49melement_dtype, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m     66\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m     67\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:797\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    792\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    793\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    794\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    795\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    796\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    798\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    799\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    801\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:735\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    733\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    734\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 735\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    736\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    737\u001b[0m     compute_device)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3800\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3797\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3800\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3801\u001b[0m       node_def,\n\u001b[0;32m   3802\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3803\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3804\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3805\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3806\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3807\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3808\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3809\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3810\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2108\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   2105\u001b[0m     control_input_ops\u001b[39m.\u001b[39mappend(control_op)\n\u001b[0;32m   2107\u001b[0m \u001b[39m# Initialize c_op from node_def and other inputs\u001b[39;00m\n\u001b[1;32m-> 2108\u001b[0m c_op \u001b[39m=\u001b[39m _create_c_op(g, node_def, inputs, control_input_ops, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   2109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_from_c_op(c_op\u001b[39m=\u001b[39mc_op, g\u001b[39m=\u001b[39mg)\n\u001b[0;32m   2111\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_op \u001b[39m=\u001b[39m original_op\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\benit\\anaconda3\\envs\\NLP\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1966\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def, extract_traceback)\u001b[0m\n\u001b[0;32m   1962\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1963\u001b[0m                                          serialized)\n\u001b[0;32m   1965\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1967\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1968\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#early stopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, verbose=1, mode='auto')\n",
    "history = model.fit(x_train, y_train, batch_size = 2056 , validation_data = (x_val,y_val) , epochs = 1000, callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model on Training Data is - \" , model.evaluate(x_train,y_train)[1]*100)\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(x_val,y_val)[1]*100)\n",
    "print(\"Accuracy of the model on Testing Data is - \" , model.evaluate(x_test,y_test)[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot accuracy and loss\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maschine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def evaluate_models(x_train_vec, y_train_ml, x_val_vec, y_val_ml, x_test_vec, y_test_ml):\n",
    "    # Define the models to be compared\n",
    "    models = [\n",
    "\n",
    "        ('Ridge Classifier', RidgeClassifier(random_state=187)),\n",
    "        ('Multinomial Naive Bayes', MultinomialNB()),\n",
    "        ('Bernoulli Naive Bayes', BernoulliNB()),\n",
    "        ('Logistic Regression', LogisticRegression(random_state=187, max_iter=10000,n_jobs=-1)),\n",
    "        ('Decision Tree', DecisionTreeClassifier(random_state=187)),\n",
    "        ('Gradient Boosting', GradientBoostingClassifier(random_state=187)),\n",
    "        ('XGBoost', XGBClassifier(random_state=187,n_jobs=-1)),\n",
    "        ('LightGBM', LGBMClassifier(random_state=187,n_jobs=-1)),\n",
    "        ('SVM', SVC(kernel='rbf',random_state=187)),\n",
    "        ('LinearSVC', LinearSVC(random_state=187)),\n",
    "        ('ExtraTrees', ExtraTreesClassifier(random_state=187,n_jobs=-1)),\n",
    "        ('PassiveAggressive', PassiveAggressiveClassifier(random_state=187, n_jobs=-1))\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Create an empty dataframe to store the results\n",
    "    results_df = pd.DataFrame(columns=['Model', 'Train Score', 'Validation Score', 'Test Score'])\n",
    "\n",
    "    # Evaluate the models using 5-fold cross-validation\n",
    "    kfold = KFold(n_splits=5, random_state=187, shuffle=True)\n",
    "    for name, model in models:\n",
    "        cv_results = cross_val_score(model, x_train_vec, y_train_ml, cv=kfold, scoring='accuracy', n_jobs=-1)\n",
    "        train_score = cv_results.mean()\n",
    "        validation_score = model.fit(x_train_vec, y_train_ml).score(x_val_vec, y_val_ml)\n",
    "        test_score = model.fit(x_train_vec, y_train_ml).score(x_test_vec, y_test_ml)\n",
    "        #predict\n",
    "        y_pred = model.predict(x_val_vec)\n",
    "        #print classification report\n",
    "        print(classification_report(y_val_ml, y_pred))\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([[name, train_score, validation_score, test_score]],\n",
    "                                                          columns=['Model', 'Train Score', 'Validation Score', 'Test Score'])],\n",
    "                               ignore_index=True)\n",
    "        print(f\"{name}: Train Score: {train_score:.2f}, Validation Score: {validation_score:.2f}, Test Score: {test_score:.2f}\")\n",
    "\n",
    "    # Return the results dataframe\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#result_count= evaluate_models(X_train_binary, y_train_ml, X_val_binary, y_val_ml, X_test_binary, y_test_ml)\n",
    "\n",
    "#result_TFID= evaluate_models(x_train_vec, y_train_ml, x_val_vec, y_val_ml, x_test_vec, y_test_ml)\n",
    "\n",
    "#result_hash = evaluate_models(train_x_hashing, y_train_ml, valid_x_hashing, y_val_ml, test_x_hashing, y_test_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def plot_model_scores(results_df, title):\n",
    "    # Sort results dataframe by test score\n",
    "    results_df = results_df.sort_values(by='Test Score', ascending=False)\n",
    "\n",
    "    # Plot bar chart of model scores\n",
    "    results_df.plot(x='Model', y=['Train Score', 'Validation Score', 'Test Score'], kind='bar', figsize=(15, 5), title=title)\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.yticks(np.arange(0, 1.1, step=0.1))\n",
    "    plt.grid(axis='y')\n",
    "    plt.grid(axis='x')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mDas Ausführen von Zellen mit \"c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda\\python.exe\" erfordert das Paket ipykernel.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -p c:\\Users\\benit\\Documents\\CDS\\04_FS23\\Natural Language Processing_cds-1091\\Projekt\\.conda ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#plot_model_scores(result_TFID, 'TF-IDF Vectorizer')\n",
    "#plot_model_scores(result_count, 'Count Vectorizer')\n",
    "#plot_model_scores(result_hash, 'Hashing Vectorizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'fit_prior': False, 'class_prior': [0.5, 0.5], 'binarize': 0.41400000000000026, 'alpha': 0.6850000000000005}\n",
      "Best score:  0.804093567251462\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "param_dist = {\n",
    "    'alpha': np.arange(0.1, 1.1, 0.001),\n",
    "    'binarize': np.arange(0.1, 1.1, 0.001),\n",
    "    'fit_prior': [True,False],\n",
    "    'class_prior': [None, [0.5, 0.5]]\n",
    "}\n",
    "\n",
    "model = BernoulliNB()\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions=param_dist, \n",
    "    n_iter=1000, \n",
    "    cv=5, \n",
    "    scoring='accuracy', \n",
    "    random_state=187,\n",
    "    error_score=np.nan,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train_binary, y_train_ml)\n",
    "\n",
    "print(\"Best params: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      2266\n",
      "           1       0.80      0.76      0.78      2010\n",
      "\n",
      "    accuracy                           0.80      4276\n",
      "   macro avg       0.80      0.80      0.80      4276\n",
      "weighted avg       0.80      0.80      0.80      4276\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mActual\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     13\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m---> 14\u001b[0m feature_names \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39mget_feature_names()\n\u001b[0;32m     16\u001b[0m \u001b[39m# Get the log probabilities for each feature given each class\u001b[39;00m\n\u001b[0;32m     17\u001b[0m log_probs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfeature_log_prob_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "#model with best params\n",
    "model = BernoulliNB(fit_prior= False, class_prior= None, binarize= 0.41400000000000026, alpha = 0.6850000000000005)\n",
    "model.fit(X_train_binary, y_train_ml)\n",
    "y_pred = model.predict(X_val_binary)\n",
    "print(classification_report(y_val_ml, y_pred))\n",
    "\n",
    "#visual representation of confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_val_ml, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words for class 0:\n",
      "aaa: -9.473\n",
      "lexicon: -9.473\n",
      "lhabab: -9.473\n",
      "liability: -9.473\n",
      "libations: -9.473\n",
      "libbing: -9.473\n",
      "libby: -9.473\n",
      "liberace: -9.473\n",
      "lewinsky: -9.473\n",
      "liberates: -9.473\n",
      "\n",
      "Top 10 words for class 1:\n",
      "laverne: -9.390\n",
      "egypt: -9.390\n",
      "egregious: -9.390\n",
      "egos: -9.390\n",
      "productions: -9.390\n",
      "egidio: -9.390\n",
      "professes: -9.390\n",
      "efron: -9.390\n",
      "efforts: -9.390\n",
      "effortless: -9.390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = C_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get the log probabilities for each feature given each class\n",
    "log_probs = model.feature_log_prob_\n",
    "\n",
    "# Sort the log probabilities by class and by feature\n",
    "sorted_log_probs = np.argsort(log_probs, axis=1)\n",
    "\n",
    "# Print the top 5 words for each class\n",
    "n_top_words = 10\n",
    "for i in range(model.classes_.size):\n",
    "    class_name = model.classes_[i]\n",
    "    print(f'Top {n_top_words} words for class {class_name}:')\n",
    "    for j in sorted_log_probs[i, :n_top_words]:\n",
    "        print(f'{feature_names[j]}: {log_probs[i, j]:.3f}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
